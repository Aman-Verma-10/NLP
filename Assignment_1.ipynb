{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5CleKO64Ow1",
        "colab_type": "text"
      },
      "source": [
        "**Tokenization of words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPwcxPhU36bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "4339103f-2f4f-4e53-f7f2-38a4b45c20bb"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2yPI_Zo5QUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bfeb2119-8196-4cbc-de3a-47f397198f23"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"A.P.J. Abdul Kalam (Fullname: Avul Pakir Jainulabdeen Abdul Kalam) served as the 11th president of the Republic of India between 2002 and 2007. He was an inspiring teacher, and a narrative author, and a great scientist..\"\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A.P.J', '.', 'Abdul', 'Kalam', '(', 'Fullname', ':', 'Avul', 'Pakir', 'Jainulabdeen', 'Abdul', 'Kalam', ')', 'served', 'as', 'the', '11th', 'president', 'of', 'the', 'Republic', 'of', 'India', 'between', '2002', 'and', '2007', '.', 'He', 'was', 'an', 'inspiring', 'teacher', ',', 'and', 'a', 'narrative', 'author', ',', 'and', 'a', 'great', 'scientist..']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_SxC335yJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ed7246e9-c70b-44d8-d7c5-9a3e1186e756"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"A.P.J. Abdul Kalam (Fullname: Avul Pakir Jainulabdeen Abdul Kalam) served as the 11th president of the Republic of India between 2002 and 2007. He was an inspiring teacher, and a narrative author, and a great scientist..\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A.P.J.', 'Abdul Kalam (Fullname: Avul Pakir Jainulabdeen Abdul Kalam) served as the 11th president of the Republic of India between 2002 and 2007.', 'He was an inspiring teacher, and a narrative author, and a great scientist..']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duk2CNX_6I4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "865540ff-5996-4fdc-8b65-0c6ef6a4bd4f"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOkMirxq6RNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6f04a612-82e4-4ee5-bc01-c55da4234dde"
      },
      "source": [
        "print(stopwords.words('english'))\n",
        "\n",
        "# random sentecnce with lot of stop words\n",
        "sample_text = \"NLP is the new buzz word of the present era. It has added colours to lives of many new age entrepreneurs as a tool for personal mastery.\"\n",
        "text_tokens = word_tokenize(sample_text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "\n",
        "print(text_tokens)\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "['NLP', 'is', 'the', 'new', 'buzz', 'word', 'of', 'the', 'present', 'era', '.', 'It', 'has', 'added', 'colours', 'to', 'lives', 'of', 'many', 'new', 'age', 'entrepreneurs', 'as', 'a', 'tool', 'for', 'personal', 'mastery', '.']\n",
            "['NLP', 'new', 'buzz', 'word', 'present', 'era', '.', 'It', 'added', 'colours', 'lives', 'many', 'new', 'age', 'entrepreneurs', 'tool', 'personal', 'mastery', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Arz6Q_c6Vlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d78daf45-1c7f-4cea-f4ce-9bc5a777b05e"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "\n",
        "porterStemmer = PorterStemmer()\n",
        "\n",
        "sentence=\"NLP is a pragmatic school of thought - an 'epistemology' - that addresses the many levels involved in being human.\"\n",
        "wordList = nltk.word_tokenize(sentence)\n",
        "\n",
        "stemWords = [porterStemmer.stem(word) for word in wordList]\n",
        "\n",
        "print(' '.join(stemWords))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nlp is a pragmat school of thought - an 'epistemolog ' - that address the mani level involv in be human .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sKTIL1380C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bb9ebcab-5f0c-4d05-8122-6c4fd3496a62"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"NLP is the practice of understanding how people organise their thinking, feeling, language and behaviour to produce the results they do.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word                Lemma               \n",
            "NLP                 NLP                 \n",
            "is                  is                  \n",
            "the                 the                 \n",
            "practice            practice            \n",
            "of                  of                  \n",
            "understanding       understanding       \n",
            "how                 how                 \n",
            "people              people              \n",
            "organise            organise            \n",
            "their               their               \n",
            "thinking            thinking            \n",
            "feeling             feeling             \n",
            "language            language            \n",
            "and                 and                 \n",
            "behaviour           behaviour           \n",
            "to                  to                  \n",
            "produce             produce             \n",
            "the                 the                 \n",
            "results             result              \n",
            "they                they                \n",
            "do                  do                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O57z_M4z9FbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95f70d5e-3620-408a-e01a-aa050b74bc34"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "txt = \"\"\"Python is an interpreted, high-level and general-purpose programming language.\"\"\"\n",
        "[wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(txt))]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python',\n",
              " 'be',\n",
              " 'an',\n",
              " 'interpreted',\n",
              " ',',\n",
              " 'high-level',\n",
              " 'and',\n",
              " 'general-purpose',\n",
              " 'programming',\n",
              " 'language',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}